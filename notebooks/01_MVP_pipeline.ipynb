{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af1a1781-19d7-4eaa-ad68-663bc0148dff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "\n",
    "\n",
    "from dpp_helpline_qa.model_validation.model_validation import cal_em_score, calculate_semantic_similarity\n",
    "from dpp_helpline_qa.modelling.question_answer import load_model_flan, answer_question_flan\n",
    "from dpp_helpline_qa.modelling.semantic_search import load_model_ss, context_ranking\n",
    "from dpp_helpline_qa.preprocessing.preprocessing import process_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config/config.yaml') as cf_file:\n",
    "    config = yaml.safe_load(cf_file.read())\n",
    "    \n",
    "max_length = config['preprocessing']['max_context_length']\n",
    "vector_method = config['preprocessing']['vector_simalirity_method']\n",
    "nclus_ivf = config['preprocessing']['nclus_ivf']\n",
    "model_semantic = config['modelling']['semantic_model']\n",
    "qna_model = config['modelling']['qna_model']\n",
    "use_gpu = config['modelling']['use_gpu']\n",
    "top_k_context = config['modelling']['top_k_context']\n",
    "min_ans_length = config['modelling']['min_ans_length']\n",
    "max_ans_length = config['modelling']['max_ans_length']\n",
    "no_repeat_ngram_size = config['modelling']['no_repeat_ngram_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(\"..\", \"data\", \"*\", \"*.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "936bfc87-4d47-4ab0-b0d0-029fc3e733e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_ss, tokenizer_ss = load_model_ss(model_semantic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f3f8ad4-fbb6-4c73-9c43-7036a4e6ac8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load and pre-process the documents to prepare for searching\n",
    "import time\n",
    "st = time.time()\n",
    "para_dfs = process_docs(files, output_path, model_ss, tokenizer_ss, max_length, vector_method, nclus_ivf) \n",
    "para_dfs[0].head()\n",
    "time.time() -st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f23eebf9-2f45-468c-ab45-0c28047a7b5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# identify the pre-processed files for searching\n",
    "op_files = glob.glob(os.path.join(output_path,'*/*.*'))\n",
    "len(op_files), op_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7390257d-cdd1-42a0-8c8c-1b3ce805807e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the model and tokenizer for question and answering\n",
    "model_qa, tokenizer_qa = load_model_flan(qna_model, use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ded9b1a-5040-4918-847f-92672ee4ede7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# automatic evaluation process\n",
    "import time\n",
    "st = time.time()\n",
    "answers = pd.read_excel('LLM_QA.xlsx')\n",
    "context = []\n",
    "final_ans = []\n",
    "EM_score_ans = []\n",
    "Sbert_score_ans = []\n",
    "NLP_score_ans = []\n",
    "EM_score_context = []\n",
    "Sbert_score_context = []\n",
    "NLP_score_context = []\n",
    "main_context_store = []\n",
    "for con in range(1, top_k_context + 1):\n",
    "    exec(f'ContextRef_{con} = []')\n",
    "no_ques = answers.shape[0]\n",
    "for i in range(no_ques): #\n",
    "    question = answers['Question'][i]\n",
    "    topic = answers['Primary Topic'][i]\n",
    "    actual_ans = answers['Answer'][i]\n",
    "    op_files = glob.glob(os.path.join(output_path,topic,'*.csv'))\n",
    "    context_df = context_ranking(question, op_files, model_ss, tokenizer_ss, vector_method)\n",
    "    # answer generated from top 5 contexts\n",
    "    main_context = '\\n'.join(context_df['content'].values[0:top_k_context])\n",
    "    # to store in csv with marking\n",
    "    main_context_store = '\\n------\\n'.join(context_df['content'].values[0:top_k_context])\n",
    "    # answer generated from only 1st context\n",
    "    context.append(main_context_store)\n",
    "    # QA\n",
    "    output = answer_question_flan(model_qa, tokenizer_qa, main_context, question, use_gpu, min_ans_length,\n",
    "    max_ans_length, no_repeat_ngram_size)\n",
    "    final_ans.append(output)\n",
    "    # output scoring\n",
    "    EM_score_ans.append(cal_em_score(output, actual_ans))\n",
    "    sim_score_ans = calculate_semantic_similarity(model_ss, tokenizer_ss, output, actual_ans) #model_val\n",
    "    Sbert_score_ans.append(sim_score_ans[1])\n",
    "    NLP_score_ans.append(sim_score_ans[2])\n",
    "    # context scoring\n",
    "    EM_score_context.append(cal_em_score(main_context, actual_ans))\n",
    "    sim_score_cnxt = calculate_semantic_similarity(model_ss, tokenizer_ss, main_context, actual_ans) #model_val\n",
    "    Sbert_score_context.append(sim_score_cnxt[1])\n",
    "    NLP_score_context.append(sim_score_cnxt[2])\n",
    "    # adding context reference\n",
    "    for con in range(0, top_k_context):\n",
    "        temp = str(context_df[\"doc_name\"].values[con])+ ';' + str(context_df[\"page\"].values[con])\n",
    "        var_list = globals()[f\"ContextRef_{con+1}\"] \n",
    "        var_list.append(temp)                                     \n",
    "\n",
    "time.time() -st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eef7b19d-049c-4e1e-bb66-65338e350458",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "answers['Extracted context'] = context\n",
    "answers['Final answer'] = final_ans\n",
    "answers['EM_Score_ans'] = EM_score_ans\n",
    "answers['Sbert_score_ans'] = Sbert_score_ans\n",
    "answers['NLP_score_ans'] = NLP_score_ans\n",
    "answers['EM_Score_context'] = EM_score_context\n",
    "answers['Sbert_score_context'] = Sbert_score_context\n",
    "answers['NLP_score_context'] = NLP_score_context\n",
    "for con in range(0, top_k_context):\n",
    "    answers[f'ContextRef_{con+1}'] = globals()[f\"ContextRef_{con+1}\"] \n",
    "answers.to_csv('ques_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bfb5842-b49f-4e78-9031-657f4cf48328",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for col in answers.columns[9:]:\n",
    "    print(f\"{col}_mean: {round(answers[col].mean(), 2)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_MVP_pipeline",
   "widgets": {}
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
