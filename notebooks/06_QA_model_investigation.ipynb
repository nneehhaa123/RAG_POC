{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92da92cc-d2f6-4f8b-a9e4-5b0f5adead19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "# list of files to search\n",
    "from dpp_helpline_qa.modelling.question_answer import load_model_qa, answer_question\n",
    "from dpp_helpline_qa.modelling.semantic_search import load_model_ss, context_ranking\n",
    "from dpp_helpline_qa.preprocessing.preprocessing import process_docs\n",
    "from dpp_helpline_qa.model_validation.model_validation import cal_em_score, calculate_semantic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10a28f7a-e96b-4bf6-aa9e-86c2240e29cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Context Generation + OpenAI for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b732736-9ae4-4a32-803b-653c09e11846",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### AS, FAQ + openai\n",
    "\n",
    "\n",
    "# list of files to search\n",
    "files = [\n",
    "    os.path.join(\"..\", \"data\", \"Inventory\", \"FAQs\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Inventory\", \"Audit Standard\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Inventory\", \"KAEG part 1\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Inventory\", \"KAEG part 2\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Inventory\", \"KAEG part 3\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Inventory\", \"KAEG part 4\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Inventory\", \"KAEG part 5\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Inventory\", \"KAEG part 6\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Inventory\", \"KAEG part 7\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Materiality\", \"Audit FAQs\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Materiality\", \"FAQs 2\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Materiality\", \"Audit Standard\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Materiality\", \"KAEG part 1\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Materiality\", \"KAEG part 2\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Materiality\", \"KAEG part 3\" + \".pdf\"),\n",
    "    os.path.join(\"..\", \"data\", \"Materiality\", \"KAEG part 4\" + \".pdf\"),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# load and pre-process the documents to prepare for searching\n",
    "import time\n",
    "st = time.time()\n",
    "para_dfs = process_docs(files, model_ss, tokenizer_ss, max_length) #'Cosine',  'IVF'\n",
    "para_dfs[0].head()\n",
    "time.time() -st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c72bb91-402f-46eb-9f00-a62137684096",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the model and tokenizer for semantic search\n",
    "model_ss, tokenizer_ss = load_model_ss()\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0094ffce-25d1-4505-8abc-d0facac5cae8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# identify the pre-processed files for searching\n",
    "op_files = glob.glob('../output/*/*.csv')\n",
    "op_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17eb89df-2d67-4eb5-b8e3-15d038f9dcbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# automatic evaluation process\n",
    "import time\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer, AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('flyhero/gpt-j-6B') \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "#model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "\n",
    "\n",
    "st = time.time()\n",
    "header = 'Answer the below question based on the given context:\\n'\n",
    "answers = pd.read_excel('LLM_QA.xlsx')\n",
    "context = []\n",
    "final_ans = []\n",
    "EM_score_ans = []\n",
    "Sbert_score_ans = []\n",
    "NLP_score_ans = []\n",
    "EM_score_context = []\n",
    "Sbert_score_context = []\n",
    "NLP_score_context = []\n",
    "for i in range(8):\n",
    "    question = answers['Question'][i]\n",
    "    topic = answers['Primary Topic'][i]\n",
    "    op_files = glob.glob('../output/'+topic+'/*.csv')\n",
    "    context_df = context_ranking(question, op_files, model_ss, tokenizer_ss)\n",
    "    main_context = '\\n'.join(context_df['content'].values[0:5])\n",
    "    context.append(main_context)\n",
    "    prompt = 'Context:' + main_context + \"\\n\\n Question: \" + question + \"\\n Answer:\" \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    gen_tokens = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        # min_length=500, \n",
    "        # max_length=5000,\n",
    "        max_new_tokens=200,\n",
    "    )\n",
    "    output_ans = tokenizer.batch_decode(gen_tokens)[0]\n",
    "    ans = output_ans.split('Answer:')[1]\n",
    "    output = ans.split('Question:')[0]\n",
    "    final_ans.append(output)\n",
    "    actual_ans = answers['Answer'][i]\n",
    "    # output scoring\n",
    "    EM_score_ans.append(cal_em_score(output, actual_ans))\n",
    "    sim_score_ans = calculate_semantic_similarity(output, actual_ans)\n",
    "    Sbert_score_ans.append(sim_score_ans[1])\n",
    "    NLP_score_ans.append(sim_score_ans[2])\n",
    "    # context scoring\n",
    "    EM_score_context.append(cal_em_score(main_context, actual_ans))\n",
    "    sim_score_cnxt = calculate_semantic_similarity(main_context, actual_ans)\n",
    "    Sbert_score_context.append(sim_score_cnxt[1])\n",
    "    NLP_score_context.append(sim_score_cnxt[2])\n",
    "\n",
    "time.time() -st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef15def3-4605-424d-8028-3cb880219b5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "answers['Extracted context'] = context\n",
    "answers['Final answer'] = final_ans\n",
    "answers['EM_Score_ans'] = EM_score_ans\n",
    "answers['Sbert_score_ans'] = Sbert_score_ans\n",
    "answers['NLP_score_ans'] = NLP_score_ans\n",
    "answers['EM_Score_context'] = EM_score_context\n",
    "answers['Sbert_score_context'] = Sbert_score_context\n",
    "answers['NLP_score_context'] = NLP_score_context\n",
    "answers.to_csv('ques_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db1ce356-e0bd-44ff-b062-4cfafd4e853e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## using GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "598c9f89-bffe-4b7a-8552-2858085ce0a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from cleantext import clean\n",
    "import GPUtil\n",
    "\n",
    "import pprint as pp\n",
    "import os, gc\n",
    "\n",
    "import logging \n",
    "import numpy as np\n",
    "LOGGER = logging.getLogger()\n",
    "def gpuname():\n",
    "    # Returns the model name of the first available GPU\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "    except:\n",
    "        LOGGER.warning(\"Unable to detect GPU model. Is your GPU configured? Is Colab Runtime set to GPU?\")\n",
    "        return \"UNKNOWN\"\n",
    "    if len(gpus) == 0:\n",
    "        raise ValueError(\"No GPUs detected in the system\")\n",
    "    return gpus[0].name \n",
    "\n",
    "def gpu_mem_total():\n",
    "    # Returns the total memory of the first available GPU\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "    except:\n",
    "        LOGGER.warning(\"Unable to detect GPU model. Is your GPU configured? Is Colab Runtime set to GPU?\")\n",
    "        return np.nan\n",
    "    if len(gpus) == 0:\n",
    "        raise ValueError(\"No GPUs detected in the system\")\n",
    "    return gpus[0].memoryTotal \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4c016d2-01e4-49a8-bdac-1478a244a6cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Getting all memory using os.popen() cpu_\n",
    "cpu_total_memory, cpu_used_memory, cpu_free_memory = map(\n",
    "    int, os.popen('free -t -m').readlines()[-1].split()[1:])\n",
    "\n",
    "cpu_RAM_tot = round(cpu_total_memory / 1024, 2)\n",
    "print(cpu_RAM_tot, cpu_used_memory, cpu_free_memory)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "431e491e-5e5d-4ff9-b01c-902ddfcfb14b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpu_mem_total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a32b3070-6779-4f52-aad1-e576ee544c4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "model_6B_pars = \"flyhero/gpt-j-6B\" # see note above\n",
    "model_3B_pars = 'EleutherAI/gpt-neo-2.7B'\n",
    "model_1B_pars = \"EleutherAI/gpt-neo-1.3B\"\n",
    "\n",
    "gpu_mem = round(gpu_mem_total() / 1024, 2)\n",
    "\n",
    "if gpu_mem > 17 and cpu_RAM_tot > 36:\n",
    "    print(\"using biggest 6B model. GPU - {} GB, CPU-RAM - {} GB\".format(gpu_mem,\n",
    "                                                                    cpu_RAM_tot))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    # actual_model = AutoModelForCausalLM.from_pretrained(model_6B_pars)\n",
    "    generator = pipeline('text-generation', model=model_6B_pars, \n",
    "                         tokenizer=tokenizer, device=0) \n",
    "\n",
    "elif gpu_mem > 14 and cpu_RAM_tot > 16:\n",
    "    print(\"using medium model. GPU - {} GB, CPU-RAM - {} GB\".format(gpu_mem,\n",
    "                                                                    cpu_RAM_tot))\n",
    "    actual_model = model_3B_pars\n",
    "    generator = pipeline('text-generation', model=actual_model, \n",
    "                     device=0) \n",
    "else:\n",
    "    actual_model = model_1B_pars\n",
    "    print(\"using SMALLER model. GPU - {} GB, CPU-RAM - {} GB\".format(gpu_mem,\n",
    "                                                                    cpu_RAM_tot))\n",
    "    print(\"using the smaller {} model\".format(actual_model))\n",
    "    generator = pipeline('text-generation', model=actual_model, \n",
    "                     device=0) \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10c0263c-e004-4bad-90b8-dd0d35e01ba1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# GPT\n",
    "def clean_gpt_out(text, remove_breaks=True):\n",
    "    cleaned_text = clean(text,\n",
    "                         fix_unicode=True,               # fix various unicode errors\n",
    "                        to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "                        lower=False,                     # lowercase text\n",
    "                        no_line_breaks=remove_breaks,           # fully strip line breaks as opposed to only normalizing them\n",
    "                        no_urls=True,                  # replace all URLs with a special token\n",
    "                        no_emails=True,                # replace all email addresses with a special token\n",
    "                        no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "                        no_numbers=False,               # replace all numbers with a special token\n",
    "                        no_digits=False,                # replace all digits with a special token\n",
    "                        no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "                        no_punct=False,                 # remove punctuations\n",
    "                        replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "                        replace_with_url=\"\",\n",
    "                        replace_with_email=\"\",\n",
    "                        replace_with_phone_number=\"\",\n",
    "                        replace_with_number=\"\",\n",
    "                        replace_with_digit=\"0\",\n",
    "                        replace_with_currency_symbol=\"\",\n",
    "                        lang=\"en\"                       # set to 'de' for German special handling\n",
    "                    )\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f89faff5-1340-4604-9ff8-dfa1de099507",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ques = '''My test counts have identified differences between the physical number of items in stock and the number \n",
    "recorded in the accounts. Does this mean that I can't place any reliance on the stock count as a control?'''\n",
    "\n",
    "cc = '''My test counts have identified differences between the physical number of items in stock and the number recorded in the\n",
    "accounts. Does this mean that I can't place any reliance on the stock count as a control?\n",
    "No. If operating effectively, the client's stock count will detect and correct any errors in the stock balance recorded in the financial statements. Therefore a deviation is only identified in the control where KPMG's count differs from the client's final count and therefore an error has gone unnoticed.\n",
    "What do I do if I identify an issue during an inventory count?\n",
    "For each test count performed, there will be one of three outcomes:    \n",
    "KPMG's and management's counts both agree to the inventory records: The inventory records are not misstated.\n",
    "KPMG's and management's counts agree, but do not agree to the inventory records: In this case, management needs to update the inventory records. If the records are accurately updated, they are not misstated.\n",
    "KPMG's and management's counts do not agree: See below.\n",
    "We only get one opportunity to observe the inventory count and obtain the audit evidence we need. If we do not resolve issues on the day, they may be more difficult to resolve after the count.\n",
    "If KPMG's and management's counts do not agree, we firstly recount and agree with management what the correct quantity should be. If we conclude that management had counted incorrectly, this may represent a control deviation in management's count control (if\n",
    "we have not determined a tolerable difference)Í¾ this control deviation exists even if management updates the inventory records in agreement with our count result.\n",
    "In all cases where a difference is identified between management's and KPMG's counts, it is important for the counter to discuss with the in-charge and manager whether further work is needed. This should be done BEFORE LEAVING SITE (or before finishing the virtual count) and ensures that senior members of the engagement team can consider the potential implications of any potential\n",
    "deviations. This is true even if the individual count differences are not material, bearing in mind they may have a significant impact when we evaluate the control or the substantive sample (depending on the purpose of our count).\n",
    "Additional information may be required around the nature and cause of the deficiency, or further test counts may be required.\n",
    "Prior to leaving the count (or finishing the virtual count), it is important that we understand the process in place for any recounts and updates being made to the system. This may be later on the day of the count or potentially in the following few days after the count. The counter will need to ensure that they understand what follow up information they require, and request this prior to leaving (or finishing the virtual count). We also obtain, or request to be provided to us, copies of all count documentation (eg. count sheets) which demonstrate that all items due to be counted had been counted.\n",
    "If your audit approach is a dual purpose approach where the substantive sample size has been set based on expected controls reliance you may need to reconsider RoMM and therefore sample sizes.\n",
    "What do I need to bear in mind when I perform independent inventory counts (i.e. not counting at the same time as management's\n",
    "counts)?\n",
    "Remember that, even when we don't plan to test management's inventory count controls, ISA 501 requires us to attend management's inventory counting and perform certain specified procedures when inventory is material (ISA (UK) 501.4). This enables us to report back to management and those charged with governance if we have identified any concerns about the entity's inventory count procedures. Therefore, even when our substantive evidence will come from independent counts, we still need to attend at least one management count.   \n",
    "Even where we don't plan to test the operating effectiveness of the entity's inventory count controls, counting at the same time as management may give us additional insight into management's count process, so can be preferable in that respect. We should, therefore, plan our substantive test counts alongside management's counts for at least a proportion of our count attendance, where possible and practical. If we have concerns with management's counts, then it may be appropriate to perform our own independent counts, and we should document our rationale for this approach.\n",
    "Note that testing the entity's inventory count controls is often the most efficient and effective approach. When considering taking a fully substantive approach because the entity has not counted its inventory, or we anticipate their counts may be ineffective, first challenge management to remediate their processÍ¾ if management's process is deficient, our substantive count may identify misstatements that mean we need to ask management to investigate and correct the inventory records anyway, so it is better for them to avoid this by ensuring that their count process works before we move to our substantive testing.\n",
    "Attendance at Physical Inventory Counting \n",
    "A1.  Management ordinarily establishes procedures under which inventory is physically  counted at least once a year to serve as a basis for the preparation of the financial  statements and, if applicable, to ascertain the reliability of the entityâ€™s perpetual  inventory system. \n",
    "A2.  Attendance at physical inventory counting involves: \n",
    "Inspecting the inventory to ascertain its existence and evaluate its condition, and  performing test counts; \n",
    "Observing compliance with managementâ€™s instructions and the performance of  procedures for recording and controlling the results of the physical inventory  count; and \n",
    "Obtaining audit evidence as to the reliability of managementâ€™s count procedures. \n",
    "These procedures may serve as test of controls or substantive procedures depending  on the auditorâ€™s risk assessment, planned approach and the specific procedures \n",
    "carried out. \n",
    "A3.  Matters relevant in planning attendance at physical inventory counting (or in designing  and performing audit procedures pursuant to paragraphs 4â€“8 of this ISA (UK)) include,  for example: \n",
    "The risks of material misstatement related to inventory. \n",
    "The nature of the internal control related to inventory. \n",
    "Whether adequate procedures are expected to be established and proper  instructions issued for physical inventory counting. \n",
    "The timing of physical inventory counting. \n",
    "Whether the entity maintains a perpetual inventory system. \n",
    "The locations at which inventory is held, including the materiality of the inventory  and the risks of material misstatement at different locations, in deciding at which  locations attendance is appropriate. ISA (UK) 600 (Revised June 2016)\n",
    " deals  with the involvement of other auditors and accordingly may be relevant if such  involvement is with regards to attendance of physical inventory counting at a  remote location. \n",
    "Whether the assistance of an auditorâ€™s expert is needed. ISA (UK) 620 (Revised  June 2016)\n",
    " deals with the use of an auditorâ€™s expert to assist the auditor to  obtain sufficient appropriate audit evidence. \n",
    "Evaluate Managementâ€™s Instructions and Procedures \n",
    "A4.  Matters relevant in evaluating managementâ€™s instructions and procedures for recording  and controlling the physical inventory counting include whether they address, for  example: \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9535b334-8c92-40a7-b5a9-860a2e5b93d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "response_min_chars =  100#@param {type:\"integer\"}\n",
    "response_max_chars =  300#@param {type:\"integer\"}\n",
    "import pprint as pp\n",
    "prompt1 = 'Context:' + cc + \"\\n\\n Question: \" + ques + \"\\n Answer:\" \n",
    "response1 = generator(prompt1, do_sample=True, min_length=response_min_chars, \n",
    "                      max_length=response_max_chars,\n",
    "                      clean_up_tokenization_spaces=True,\n",
    "                      return_full_text=True)\n",
    "gc.collect()\n",
    "print(\"Prompt: \\n\")\n",
    "pp.pprint(prompt1)\n",
    "print(\"\\nResponse: \\n\")\n",
    "out1_dict = response1[0]\n",
    "pp.pprint(clean_gpt_out(out1_dict[\"generated_text\"]), compact=True)\n",
    "time.time()-st\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67147dd7-ac85-495c-9aa6-3e5a1e318bf5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7dd69c0-ac14-4707-a72f-c63dd88450dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "response_min_chars =  100#@param {type:\"integer\"}\n",
    "response_max_chars =  1000#@param {type:\"integer\"}\n",
    "import pprint as pp\n",
    "prompt1 = 'Context:' + cc + \"\\n\\n Question: \" + ques + \"\\n Answer:\" \n",
    "# input_ids = tokenizer(prompt1, return_tensors=\"pt\").input_ids\n",
    "# gen_tokens = model.generate(\n",
    "#     input_ids,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.9,\n",
    "#     max_new_tokens=200,\n",
    "# )\n",
    "# output_ans = tokenizer.batch_decode(gen_tokens)[0]\n",
    "generator = pipeline('text-generation', model=actual_model)\n",
    "                    #device=0) \n",
    "response1 = generator(prompt1, do_sample=True, \n",
    "                    max_new_tokens=100, temperature=0.9\n",
    "                   #min_length=response_min_chars, max_length=response_max_chars, clean_up_tokenization_spaces=True,return_full_text=True\n",
    "                      )\n",
    "\n",
    "gc.collect()\n",
    "pp.pprint(response1)\n",
    "\n",
    "time.time()-st\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_QA_model_investigation",
   "notebookOrigID": 4061167020581872,
   "widgets": {}
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
